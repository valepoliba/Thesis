{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydoc import importfile\n",
    "import rdflib\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from rdflib import ConjunctiveGraph\n",
    "import gc, copy, datetime\n",
    "#from pathlib import Path\n",
    "\n",
    "import os, sys\n",
    "p = os.path.abspath('..')\n",
    "sys.path.insert(1, p)\n",
    "\n",
    "from knowledge_graph import *\n",
    "\n",
    "from rdf2vec import RDF2VecTransformer\n",
    "\n",
    "from lcs_rdf_graph import LCS\n",
    "\n",
    "from rdf_graph_utils import rdf_to_plot, rdf_to_text\n",
    "\n",
    "\n",
    "def rdflib_to_kg_nquads(rdflib_g, label_predicates=[]):\n",
    "    # Iterate over quads, add s, p and o to graph and 2 edges (s-->p, p-->o)\n",
    "    # all predicates in label_predicates get excluded\n",
    "    print(rdflib_g)\n",
    "    kg = KnowledgeGraph()\n",
    "    for s, p, o, _ in rdflib_g.quads((None, None, None, None)):\n",
    "        if p not in label_predicates:\n",
    "            s_v, o_v = Vertex(str(s)), Vertex(str(o))\n",
    "            p_v = Vertex(str(p), predicate=True)\n",
    "            kg.add_vertex(s_v)\n",
    "            kg.add_vertex(p_v)\n",
    "            kg.add_vertex(o_v)\n",
    "            kg.add_edge(s_v, p_v)\n",
    "            kg.add_edge(p_v, o_v)\n",
    "\n",
    "    return kg\n",
    "\n",
    "\n",
    "def get_drug_name(graph, drug):\n",
    "    query = \"\"\"\n",
    "               SELECT ?obj\n",
    "               WHERE { ?s <http://www.w3.org/2000/01/rdf-schema#label> ?obj.\n",
    "               \"\"\".replace(\"?s\", \"<%s>\" % drug) + \"}\"\n",
    "\n",
    "    query_res = graph.query(query)\n",
    "    label = []\n",
    "    for res in query_res:\n",
    "        label.append(str(res.obj))\n",
    "\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../outputs/drugbank/testvalerio\\\\output_test_.turtle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m directory \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../../outputs/drugbank/testvalerio\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(directory \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/test.log\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m rdf_to_text(seed, directory, \u001b[39m\"\u001b[39;49m\u001b[39mturtle\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtest_\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLoading data... \u001b[39m\u001b[39m'\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m g \u001b[39m=\u001b[39m ConjunctiveGraph()\n",
      "File \u001b[1;32md:\\UniversitÃ \\Magistrale\\Magistrale\\Tesi\\Thesis\\src\\rdf_graph_utils.py:39\u001b[0m, in \u001b[0;36mrdf_to_text\u001b[1;34m(graph, path, format, name)\u001b[0m\n\u001b[0;32m     36\u001b[0m path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, file)\n\u001b[0;32m     38\u001b[0m \u001b[39m#strings = graph.serialize(format=format)\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path, \u001b[39m'\u001b[39;49m\u001b[39mr+b\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     40\u001b[0m     f\u001b[39m.\u001b[39mwrite(graph)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../outputs/drugbank/testvalerio\\\\output_test_.turtle'"
     ]
    }
   ],
   "source": [
    "print(end='Loading data... ', flush=True)\n",
    "g = ConjunctiveGraph()\n",
    "\n",
    "g.parse('../../datasets/drugbank/drugbank.nq', format=\"nquads\")\n",
    "print('OK')\n",
    "#\n",
    "# # Extract all database drugs' URI\n",
    "all_drugs_file = pd.read_csv('../../datasets/drugbank/all_drugs.tsv', sep='\\t')\n",
    "all_drugs = [rdflib.URIRef(x) for x in all_drugs_file['drug']]\n",
    "#\n",
    "# # Define irrelevant predicates\n",
    "predicates = pd.read_csv('../../datasets/drugbank/bad_predicates.tsv', sep='\\t')\n",
    "predicates = [rdflib.URIRef(x) for x in predicates['predicate']]\n",
    "#\n",
    "\n",
    "stop_patterns = pd.read_csv('../../datasets/drugbank/stop_patterns.tsv', sep='\\t')\n",
    "stop_patterns = [x for x in stop_patterns['stopping_patterns']]\n",
    "\n",
    "preds = pd.read_csv('../../datasets/drugbank/uninformative.tsv', sep='\\t')\n",
    "preds = [rdflib.URIRef(x) for x in preds['uninformative']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kg = rdflib_to_kg_nquads(g, label_predicates=predicates)\n",
    "\n",
    "del g\n",
    "gc.collect()\n",
    "\n",
    "#\n",
    "# # %%\n",
    "# # estraggo un'istanza di knowledge graph per ogni drug presente in quello iniziale\n",
    "\n",
    "kg_depth = 4\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "kv = []\n",
    "drugs = []\n",
    "graphs = []\n",
    "\n",
    "for drug in all_drugs:\n",
    "    try:\n",
    "        gi = extract_instance(kg, drug, kg_depth)\n",
    "        graphs.append(gi)\n",
    "        drugs.append(drug)\n",
    "        kv.append({'graph': gi, 'resource': drug})\n",
    "        i += 1\n",
    "    except Exception as e:\n",
    "        j += 1\n",
    "\n",
    "print('ok:' + str(i))\n",
    "print('not imported: ' + str(j))\n",
    "\n",
    "del kg\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Embeddings\n",
    "transformer = RDF2VecTransformer(wl=False, max_path_depth=4, vector_size=15, walks_per_graph=1)\n",
    "# transformer = RDF2VecTransformer()\n",
    "transformer.fit(graphs, drugs)\n",
    "embeddings = transformer.transform(graphs, drugs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# STAMPO PER OGNI RISORSA IL CLUSTER A CUI CORRISPONDE, IN MODO DA POTERNE PRELEVARE PER IL MOMENTO\n",
    "# DUE APPARTENENTI ALLO STESSO CLUSTER\n",
    "kmeans = KMeans(n_clusters=250)\n",
    "km = kmeans.fit(embeddings)\n",
    "y_kmeans = kmeans.predict(embeddings)\n",
    "\n",
    "print(\"clustering models created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "clusters = {i: [] for i in range(kmeans.n_clusters)}\n",
    "i = 0\n",
    "for j in y_kmeans:\n",
    "    clusters[j].append(i)\n",
    "    i += 1\n",
    "\n",
    "# Save clusters obtained from kmeans\n",
    "#file = open(\"../../datasets/drugbank/clusters_log/kmeans_125_\" + str(datetime.datetime.now()), \"a\")\n",
    "#file = Path(\"../../datasets/drugbank/clusters_log/kmeans_125_\" + str(datetime.datetime.now())).mkdir(parents=True, exist_ok=True)\n",
    "file = open(\"../../datasets/drugbank/clusters_log/kmeans_125_2\", \"a\")\n",
    "file.write(str(clusters))\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print clusters and their dimension\n",
    "\n",
    "for key in clusters.keys():\n",
    "    print(\"cluster \" + str(key) + \" with dimension: \" + str(len(clusters[key])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "directory = \"../../outputs/drugbank/oLast_NQ_NEW\"\n",
    "if not os.path.exists(directory):\n",
    "    os.mkdir(directory)\n",
    "\n",
    "\n",
    "# cluster da analizzare\n",
    "# k = 22\n",
    "\n",
    "# seleziono il cluster con il minor numero di elementi\n",
    "\n",
    "k = min(clusters.keys(), key=lambda a: len(clusters[a]))\n",
    "\n",
    "# seleziono il cluster con il minor numero totale di archi\n",
    "\n",
    "# k = min(clusters.keys(), \n",
    "#        key=lambda key: sum(len(kg_to_rdflib(graphs[res], kg_depth)) for res in clusters[key]))\n",
    "\n",
    "# seleziono il cluster con l'elemento che ha il minor numero di archi\n",
    "\n",
    "# k = min(clusters.keys(), key=lambda key: min([len(kg_to_rdflib(graphs[res], kg_depth))\n",
    "#                                                 for res in clusters[key]]))\n",
    "\n",
    "\n",
    "clusters[k] = sorted(clusters[k],  key=lambda res: len(kg_to_rdflib(graphs[res], kg_depth)))\n",
    "\n",
    "# clusters[k] = [48, 50]\n",
    "\n",
    "L = len(clusters[k])\n",
    "\n",
    "print(\"esploro il cluster: \" + str(k) + \" con dimensione \" + str(L))\n",
    "print(clusters[k])\n",
    "# risorsa iniziale\n",
    "# resource_1 = random.choice(clusters[k])\n",
    "\n",
    "resource_1 = clusters[k].pop(0)\n",
    "\n",
    "graph_1 = graphs[resource_1]\n",
    "\n",
    "print(\"risorsa iniziale: \" + str(resource_1) + \" di dim -> \" + str(len(kg_to_rdflib(graph_1, kg_depth))))\n",
    "\n",
    "# clusters[k].remove(resource_1)\n",
    "explored_resoures = [resource_1]\n",
    "\n",
    "iteration = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# file = open(directory + \"/tmp_LCS.log\", \"a\")\n",
    "\n",
    "while clusters[k]:\n",
    "    # try:\n",
    "        file = open(directory + \"/tmp_LCS.log\", \"a\")\n",
    "        \n",
    "        # resource_2 = random.choice(clusters[k])\n",
    "   \n",
    "        resource_2 = clusters[k].pop(0)\n",
    "        graph_2 = graphs[resource_2]\n",
    "        print(\"LCS with resource: \" + str(resource_2) \n",
    "              + \" con dim: \" + str(len(kg_to_rdflib(graph_2, kg_depth))))\n",
    "        # clusters[k].remove(resource_2)\n",
    "\n",
    "        # seed\n",
    "        seed = LCS(graph_1, graph_2, depth=2, stop_patterns=stop_patterns, uninformative_triples=preds)\n",
    "        seed.find()\n",
    "              \n",
    "        explored_resoures.append(resource_2)\n",
    "        \n",
    "        print(\"dim LCS itermedio tra \" + str(explored_resoures) + \" \\n--> \" + str(len(seed)))\n",
    "        \n",
    "        del graph_1\n",
    "        del graph_2\n",
    "        gc.collect()\n",
    "        \n",
    "        graph_1 = copy.deepcopy(seed)\n",
    "\n",
    "        print(\"Iterazione: \" + str(iteration) + \", trovato LCS tra: \" + str(explored_resoures))\n",
    "        rdf_to_text(seed, directory, \"turtle\", \"tmp_LCS_\" + str(iteration))\n",
    "        rdf_to_text(seed, directory, \"nt\", \"tmp_LCS_\" + str(iteration))\n",
    "        \n",
    "        del seed\n",
    "        gc.collect()\n",
    "        \n",
    "        file.write(\"Iterazione: \" + str(iteration) +  \" risorse esplorate: \" + str(explored_resoures) + \"\\n\")\n",
    "        file.close()\n",
    "        \n",
    "        iteration += 1\n",
    "        \"\"\"\n",
    "        except Exception as e:\n",
    "            print(\"got exception: \" + str(e))\n",
    "            file.close()\n",
    "        \"\"\"\n",
    "# file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rdf_to_plot(graph_1, directory)\n",
    "print(\"LCS finale tra le risorse: \" + str(explored_resoures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SALVATAGGIO DEL GRAFO\n",
    "\n",
    "rdf_to_text(graph_1, directory, 'turtle', 'final_LCS')\n",
    "rdf_to_text(graph_1, directory, 'nt', 'final_LCS')\n",
    "file =  open(directory + \"/final_LCS_resources.log\", \"a\")\n",
    "file.write(str(explored_resoures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(end='Loading data... ', flush=True)\n",
    "g = ConjunctiveGraph()\n",
    "\n",
    "g.parse('../../datasets/drugbank/drugbank.nq', format=\"nquads\")\n",
    "print('OK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file.write(\"\\n ####### \\n\")\n",
    "\n",
    "explored_resources_names = []\n",
    "\n",
    "for drug_index in explored_resoures:\n",
    "    drug_name = get_drug_name(g, drugs[drug_index])\n",
    "    explored_resources_names.extend(drug_name)\n",
    "\n",
    "file.write(str(explored_resources_names))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del g\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "f337ac061ce9696b0f1ec4c1d557fc964de9fc8c97f461bc871446d45fc96448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
